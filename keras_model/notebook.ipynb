{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your own model\n",
    "\n",
    "1. Install Python and pip (Py Package Manager) on your computer (instructions are available online). I used python 2.7\n",
    "2. Install these packages with pip: keras with tensorflow, jupyter notebook, sklearn, requests, h5py (google how to do it on your platform)\n",
    "3. Download [train_sample.csv](https://hackiit.slack.com/files/U70G56S3C/F75UCE2CE/train_sample.csv) (reduced training data set with 5 labels)\n",
    "4. Download this notebook and put it in a folder!\n",
    "5. Follow [me](http://github.com/bolein) on github :D\n",
    "5. Run jupyter notebook and open this file (notebook)\n",
    "4. Run below cells one by one following the instructions\n",
    "5. Ask in Slack if you have any questions or problems\n",
    "6. Have fun!\n",
    "\n",
    "There's a good set of articles to get an idea about the neural networks http://neuralnetworksanddeeplearning.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# install my custom directory iterator for keras (feel fre to go and star it)\n",
    "# https://github.com/bolein/keras_img_iterator\n",
    "!pip install --user git+https://github.com/bolein/keras_img_iterator.git --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Now restart your kernel with Kernel -> Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Download the data (Run this cell only once! It may take some time!)\n",
    "\n",
    "## Load Libraries\n",
    "import os\n",
    "import requests, zipfile, io\n",
    "\n",
    "# load data into platform\n",
    "url = requests.get('https://he-s3.s3.amazonaws.com/media/hackathon/deep-learning-challenge-1/identify-the-objects/a0409a00-8-dataset_dp.zip')\n",
    "data = zipfile.ZipFile(io.BytesIO(url.content))\n",
    "data.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wait until the asterix * in the previous task dissapears\n",
    "# check if the files have been download in current directory\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Now put the file train_sample.csv inside the data directory next to your notebook file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import save_model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_img_iterator import SingleDirectoryIterator\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def convnet(num_classes, image_size):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(image_size, image_size, 3),\n",
    "                     activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D vectors\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the meta data\n",
    "# Make sure you downloaded train_sample.csv file\n",
    "meta_data = pd.read_csv('data/train_sample.csv', header=0) # change filename to train.csv for full data\n",
    "filenames = meta_data['image_id'].apply(lambda id: id + '.png').values\n",
    "labels = meta_data['label'].values\n",
    "classes = list(set(labels))\n",
    "\n",
    "# split into test and validation\n",
    "files_train, files_validate, labels_train, labels_validate = \\\n",
    "    train_test_split(filenames, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "num_train_samples = files_train.shape[0]\n",
    "num_val_samples = files_validate.shape[0]\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "batch_size = 32\n",
    "image_size = 128\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2)\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "# only rescaling\n",
    "test_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_iterator = SingleDirectoryIterator(\n",
    "    directory='data/train_img/',\n",
    "    filenames=files_train,\n",
    "    labels=labels_train,\n",
    "    classes=classes,\n",
    "    image_data_generator=train_gen,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    seed=1337)\n",
    "\n",
    "validation_iterator = SingleDirectoryIterator(\n",
    "    directory='data/train_img/',\n",
    "    filenames=files_validate,\n",
    "    labels=labels_validate,\n",
    "    classes=classes,\n",
    "    image_data_generator=test_gen,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialize and compile the model\n",
    "model = convnet(num_classes, image_size)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# only run this cell if you have previously saved model! \n",
    "# OR load from saved file (only if the model previously saved)\n",
    "# don't forget to put the right name for it\n",
    "model = load_model('model_0.321674930874.h5', compile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 2\n",
    "\n",
    "validation_iterator.reset()\n",
    "train_iterator.reset()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_iterator,\n",
    "    steps_per_epoch=num_train_samples // batch_size + 1,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_iterator,\n",
    "    validation_steps=num_val_samples // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Visualize learning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate f1-score against validation set\n",
    "validation_iterator.reset()\n",
    "loss, score = model.evaluate_generator(\n",
    "    validation_iterator,\n",
    "    steps=num_val_samples // batch_size + 1)\n",
    "\n",
    "print(\"model scored {} on validation set\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Only run these cells if you want to test your model over the test data provided from the competition\n",
    "# (Make sure you've trained on the full data)\n",
    "# Test model\n",
    "# Read test data set\n",
    "test_data = pd.read_csv('data/test.csv', header=0)\n",
    "files_test = test_data['image_id'].apply(lambda id: id + '.png').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set up iterator for test set\n",
    "test_iterator = SingleDirectoryIterator(\n",
    "    directory='data/test_img/',\n",
    "    filenames=files_test,\n",
    "    image_data_generator=test_gen,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    shuffle=False)\n",
    "\n",
    "# make prediction\n",
    "num_test_samples = files_test.shape[0]\n",
    "predictions = model.predict_generator(\n",
    "    generator=test_iterator,\n",
    "    steps=num_test_samples // batch_size + 1)\n",
    "\n",
    "test_labels = [classes[i] for i in np.argmax(predictions, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# function for downloading results\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "def create_download_link(df, filename):  \n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{filename}</a>'\n",
    "    html = html.format(payload=payload,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save to file and create download link\n",
    "submission = pd.DataFrame({'image_id':test_data.image_id, 'label':test_labels})\n",
    "create_download_link(submission, \"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model_file = 'model_{}.h5'.format(score)\n",
    "save_model(model, model_file)\n",
    "print('Training complete. model was saved as ', model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
